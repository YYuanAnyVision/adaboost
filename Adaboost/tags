!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
ADABOOST_HPP	Adaboost.hpp	2;"	d
Adaboost	Adaboost.hpp	/^class Adaboost$/;"	c
Adaboost::Apply	Adaboost.hpp	/^		bool Apply();$/;"	p	class:Adaboost	access:public	signature:()
Adaboost::SetDebug	Adaboost.cpp	/^void Adaboost::SetDebug( bool d )$/;"	f	class:Adaboost	signature:( bool d )
Adaboost::SetDebug	Adaboost.hpp	/^		void SetDebug( bool yesIwant);$/;"	p	class:Adaboost	access:public	signature:( bool yesIwant)
Adaboost::Train	Adaboost.cpp	/^bool Adaboost::Train(	const Mat &neg_data,				\/* in : neg data format-> featuredim x number0*\/$/;"	f	class:Adaboost	signature:( const Mat &neg_data, const Mat &pos_data, const int &nWeaks, const tree_para &treepara)
Adaboost::Train	Adaboost.hpp	/^		bool Train(  const Mat &neg_data,				\/* in : neg data  format-> featuredim x number0 *\/$/;"	p	class:Adaboost	access:public	signature:( const Mat &neg_data, const Mat &pos_data, const int &nWeaks, const tree_para &treepara)
Adaboost::m_debug	Adaboost.hpp	/^		bool m_debug;$/;"	m	class:Adaboost	access:private
Adaboost::m_trees	Adaboost.hpp	/^		vector<binaryTree> m_trees;$/;"	m	class:Adaboost	access:private
Apply	Adaboost.cpp	/^		bt.Apply( neg_data, h0);$/;"	p	file:	signature:( neg_data, h0)
Apply	Adaboost.cpp	/^		bt.Apply( pos_data, h1);$/;"	p	file:	signature:( pos_data, h1)
Apply	Adaboost.hpp	/^		bool Apply();$/;"	p	class:Adaboost	access:public	signature:()
H0	Adaboost.cpp	/^	Mat H0 = Mat::zeros( number_neg_samples, 1, CV_64F);$/;"	l
H1	Adaboost.cpp	/^	Mat H1 = Mat::zeros( number_pos_samples, 1, CV_64F);$/;"	l
SetDebug	Adaboost.cpp	/^		binaryTree bt; bt.SetDebug(true);$/;"	p	file:	signature:(true)
SetDebug	Adaboost.cpp	/^void Adaboost::SetDebug( bool d )$/;"	f	class:Adaboost	signature:( bool d )
SetDebug	Adaboost.hpp	/^		void SetDebug( bool yesIwant);$/;"	p	class:Adaboost	access:public	signature:( bool yesIwant)
Train	Adaboost.cpp	/^bool Adaboost::Train(	const Mat &neg_data,				\/* in : neg data format-> featuredim x number0*\/$/;"	f	class:Adaboost	signature:( const Mat &neg_data, const Mat &pos_data, const int &nWeaks, const tree_para &treepara)
Train	Adaboost.hpp	/^		bool Train(  const Mat &neg_data,				\/* in : neg data  format-> featuredim x number0 *\/$/;"	p	class:Adaboost	access:public	signature:( const Mat &neg_data, const Mat &pos_data, const int &nWeaks, const tree_para &treepara)
Train	test_adaboost.cpp	/^	ab.Train( train_neg, train_pos, 10, tree_para());$/;"	p	file:	signature:( train_neg, train_pos, 10, tree_para())
ab	test_adaboost.cpp	/^	Adaboost ab;$/;"	l
alpha	Adaboost.cpp	/^		double alpha = 1; $/;"	l
at	Adaboost.cpp	/^		errs.at<double>(c,0) = bt.getTrainError();$/;"	p	file:	signature:(c,0)
at	Adaboost.cpp	/^		losses.at<double>(c,0) = loss;$/;"	p	file:	signature:(c,0)
bt	Adaboost.cpp	/^		binaryTree bt; bt.SetDebug(true);$/;"	l
cv::exp	Adaboost.cpp	/^		cv::exp( H0, train_pack.wts0 );       train_pack.wts0 = train_pack.wts0\/(2*number_neg_samples);$/;"	p	class:cv	file:	signature:( H0, train_pack.wts0 )
endl	Adaboost.cpp	/^			cout<<"alpha is "<<alpha<<" , error is "<<error<<endl;$/;"	l
endl	Adaboost.cpp	/^			cout<<"in fuction Adaboost:Train, error training tree No "<<c<<endl;$/;"	l
endl	Adaboost.cpp	/^			cout<<"stopping early ..."<<endl;$/;"	l
endl	Adaboost.cpp	/^		cout<<"In function Adaboost:Train : data empty "<<endl;$/;"	l
endl	Adaboost.cpp	/^		cout<<"In function Adaboost:Train : neg_data and pos_data should be the same type, and having the same rows( column feature vector)"<<endl;$/;"	l
error	Adaboost.cpp	/^		double error = bt.getTrainError();$/;"	l
errs	Adaboost.cpp	/^	Mat errs   = Mat::zeros( nWeaks, 1, CV_64F);$/;"	l
exp	Adaboost.cpp	/^		cv::exp( H0, train_pack.wts0 );       train_pack.wts0 = train_pack.wts0\/(2*number_neg_samples);$/;"	p	class:cv	file:	signature:( H0, train_pack.wts0 )
feature_dim	Adaboost.cpp	/^	int feature_dim		   = neg_data.rows;$/;"	l
fs	test_adaboost.cpp	/^	FileStorage fs;$/;"	l
h0	Adaboost.cpp	/^		Mat h0, h1;										\/*  predicted labels *\/$/;"	l
h1	Adaboost.cpp	/^		Mat h0, h1;										\/*  predicted labels *\/$/;"	l
loss	Adaboost.cpp	/^		double loss = (cv::sum( train_pack.wts0))[0] + (cv::sum(train_pack.wts1))[0];$/;"	l
losses	Adaboost.cpp	/^	Mat losses = Mat::zeros( nWeaks, 1, CV_64F);$/;"	l
m_debug	Adaboost.hpp	/^		bool m_debug;$/;"	m	class:Adaboost	access:private
m_trees	Adaboost.hpp	/^		vector<binaryTree> m_trees;$/;"	m	class:Adaboost	access:private
main	test_adaboost.cpp	/^int main( int argc, char** argv)$/;"	f	signature:( int argc, char** argv)
number_neg_samples	Adaboost.cpp	/^	int number_neg_samples = neg_data.cols;$/;"	l
number_pos_samples	Adaboost.cpp	/^	int number_pos_samples = pos_data.cols;$/;"	l
push_back	Adaboost.cpp	/^		m_trees.push_back( bt );$/;"	p	file:	signature:( bt )
release	test_adaboost.cpp	/^	fs.release();$/;"	p	file:	signature:()
reserve	Adaboost.cpp	/^	m_trees.reserve( nWeaks);$/;"	p	file:	signature:( nWeaks)
scaleHs	Adaboost.cpp	/^		bt.scaleHs( alpha );$/;"	p	file:	signature:( alpha )
train_neg	test_adaboost.cpp	/^	Mat train_neg, train_pos;$/;"	l
train_neg	test_adaboost.cpp	/^	fs["matrix"]>>train_neg;$/;"	l
train_pack	Adaboost.cpp	/^	data_pack train_pack;$/;"	l
train_pos	test_adaboost.cpp	/^	Mat train_neg, train_pos;$/;"	l
train_pos	test_adaboost.cpp	/^	fs["matrix"] >>train_pos;$/;"	l
